{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploding and Vanishing Gradient Demo\n",
    "\n",
    "Source: https://github.com/grasool/explore-gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the depth of a neural netwrok generally leads to increased accuracy. However, with the increasing number of layers in a neural netwroks, the gradients of the loss function with respect to the unknown parameters (weights and biases) may either explode or vanish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Input\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.callbacks import TensorBoard\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Model\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' ### just to remove memory warnings\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Creates MLP layers \n",
    "Fits the model\n",
    "Saves the model\n",
    "Saves csv for loss and accuracy (trainig and validation)\n",
    "Saves tensorboard summary for Gradients\n",
    "@author: Ghulam Rasool\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Specify number of layers\n",
    "N_LAYERS = 25\n",
    "\n",
    "# Width of hidden layer, number of neurons in the hidden layer. all layers have same width. \n",
    "n_hwidth = 128\n",
    "batch_size = 128\n",
    "n_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "n_layers = N_LAYERS -1\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 added\n",
      "Layer 2 added\n",
      "Layer 3 added\n",
      "Layer 4 added\n",
      "Layer 5 added\n",
      "Layer 6 added\n",
      "Layer 7 added\n",
      "Layer 8 added\n",
      "Layer 9 added\n",
      "Layer 10 added\n",
      "Layer 11 added\n",
      "Layer 12 added\n",
      "Layer 13 added\n",
      "Layer 14 added\n",
      "Layer 15 added\n",
      "Layer 16 added\n",
      "Layer 17 added\n",
      "Layer 18 added\n",
      "Layer 19 added\n",
      "Layer 20 added\n",
      "Layer 21 added\n",
      "Layer 22 added\n",
      "Layer 23 added\n",
      "Layer 24 added\n",
      "Output layer added\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 493,834\n",
      "Trainable params: 487,690\n",
      "Non-trainable params: 6,144\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.8714 - accuracy: 0.7176 - val_loss: 0.4810 - val_accuracy: 0.9338\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.2646 - accuracy: 0.9352 - val_loss: 0.3073 - val_accuracy: 0.9513\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.1956 - accuracy: 0.9529 - val_loss: 0.3824 - val_accuracy: 0.9608\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.1582 - accuracy: 0.9619 - val_loss: 0.2878 - val_accuracy: 0.9655\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.1416 - accuracy: 0.9664 - val_loss: 0.3150 - val_accuracy: 0.9657\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.1220 - accuracy: 0.9715 - val_loss: 0.2423 - val_accuracy: 0.9704\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.1059 - accuracy: 0.9747 - val_loss: 0.2289 - val_accuracy: 0.9708\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.1018 - accuracy: 0.9758 - val_loss: 0.1632 - val_accuracy: 0.9721\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.0901 - accuracy: 0.9786 - val_loss: 0.2332 - val_accuracy: 0.9665\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.0833 - accuracy: 0.9807 - val_loss: 0.1218 - val_accuracy: 0.9752\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.0786 - accuracy: 0.9816 - val_loss: 0.1513 - val_accuracy: 0.9751\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.0704 - accuracy: 0.9832 - val_loss: 0.1377 - val_accuracy: 0.9733\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.0678 - accuracy: 0.9836 - val_loss: 0.1855 - val_accuracy: 0.9704\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.0599 - accuracy: 0.9858 - val_loss: 0.1237 - val_accuracy: 0.9772\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.0591 - accuracy: 0.9861 - val_loss: 0.1120 - val_accuracy: 0.9774\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.0560 - accuracy: 0.9870 - val_loss: 0.1024 - val_accuracy: 0.9794\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.0510 - accuracy: 0.9886 - val_loss: 0.1448 - val_accuracy: 0.9782\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.0468 - accuracy: 0.9892 - val_loss: 0.1227 - val_accuracy: 0.9755\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.0483 - accuracy: 0.9889 - val_loss: 0.1150 - val_accuracy: 0.9782\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.0489 - accuracy: 0.9893 - val_loss: 0.1479 - val_accuracy: 0.9778\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(784,))\n",
    "\n",
    "def fCreate_Layers(n_layers, inputs):\n",
    "    x = inputs\n",
    "    for k in range(n_layers):\n",
    "        x = Dense(n_hwidth)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        print('Layer %d added' % (k+1))\n",
    "        \n",
    "    return x\n",
    "\n",
    "# Create all layers    \n",
    "x_all = fCreate_Layers(n_layers, inputs)\n",
    "# Output layer\n",
    "predictions = Dense(n_classes, activation='softmax')(x_all)\n",
    "print('Output layer added')\n",
    "# Create Model\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "model_name = 'MLP_No_SKIP_%s.h5' % N_LAYERS\n",
    "csv_name = 'MLP_No_SKIP_%s.csv' % N_LAYERS\n",
    "\n",
    "model.save(model_name)\n",
    "pandas.DataFrame(history.history).to_csv(csv_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\"\"\"\n",
    "Creates MLP layers with skip connections\n",
    "Fits the model\n",
    "Saves the model\n",
    "Saves csv for loss and accuracy (trainig and validation)\n",
    "Saves tensorboard summary for Gradients\n",
    "@author: Ghulam Rasool\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(784,))\n",
    "\n",
    "def fCreate_Layers(n_layers, inputs):\n",
    "    x = Dense(n_hwidth)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    print('Layer 1 added')\n",
    "    \n",
    "    n_skip_layers = math.floor(n_layers/2)\n",
    "    \n",
    "    for k in range(n_skip_layers):\n",
    "        x = Dense(n_hwidth)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        print('Layer %d added' % (2*k+2))\n",
    "        \n",
    "        y = Dense(n_hwidth)(x)\n",
    "        y = BatchNormalization()(y)\n",
    "        x = keras.layers.add([y, x])\n",
    "        x = Activation('relu')(x)\n",
    "        print('Layer %d with skip connection  added' % (2*k+3))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 added\n",
      "Layer 2 added\n",
      "Layer 3 with skip connection  added\n",
      "Layer 4 added\n",
      "Layer 5 with skip connection  added\n",
      "Layer 6 added\n",
      "Layer 7 with skip connection  added\n",
      "Layer 8 added\n",
      "Layer 9 with skip connection  added\n",
      "Layer 10 added\n",
      "Layer 11 with skip connection  added\n",
      "Layer 12 added\n",
      "Layer 13 with skip connection  added\n",
      "Layer 14 added\n",
      "Layer 15 with skip connection  added\n",
      "Layer 16 added\n",
      "Layer 17 with skip connection  added\n",
      "Layer 18 added\n",
      "Layer 19 with skip connection  added\n",
      "Layer 20 added\n",
      "Layer 21 with skip connection  added\n",
      "Layer 22 added\n",
      "Layer 23 with skip connection  added\n",
      "Layer 24 added\n",
      "Layer 25 with skip connection  added\n",
      "Output layer added\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 784)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 128)          100480      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 128)          512         dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 128)          0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 128)          16512       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 128)          512         dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 128)          0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 128)          16512       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 128)          512         dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 128)          0           batch_normalization_28[0][0]     \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 128)          0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 128)          16512       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 128)          512         dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 128)          0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 128)          16512       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 128)          512         dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128)          0           batch_normalization_30[0][0]     \n",
      "                                                                 activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 128)          0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 128)          16512       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 128)          512         dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 128)          0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 128)          16512       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 128)          512         dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 128)          0           batch_normalization_32[0][0]     \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 128)          0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 128)          16512       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 128)          512         dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 128)          0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 128)          16512       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 128)          512         dense_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128)          0           batch_normalization_34[0][0]     \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 128)          0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 128)          16512       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 128)          512         dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 128)          0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 128)          16512       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 128)          512         dense_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128)          0           batch_normalization_36[0][0]     \n",
      "                                                                 activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 128)          0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 128)          16512       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 128)          512         dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 128)          0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 128)          16512       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 128)          512         dense_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 128)          0           batch_normalization_38[0][0]     \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 128)          0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 128)          16512       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 128)          512         dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 128)          0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 128)          16512       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 128)          512         dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 128)          0           batch_normalization_40[0][0]     \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 128)          0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 128)          16512       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 128)          512         dense_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 128)          0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 128)          16512       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 128)          512         dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 128)          0           batch_normalization_42[0][0]     \n",
      "                                                                 activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 128)          0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 128)          16512       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 128)          512         dense_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 128)          0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 128)          16512       activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 128)          512         dense_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 128)          0           batch_normalization_44[0][0]     \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 128)          0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 128)          16512       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 128)          512         dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 128)          0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 128)          16512       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 128)          512         dense_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 128)          0           batch_normalization_46[0][0]     \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 128)          0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 128)          16512       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 128)          512         dense_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 128)          0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 128)          16512       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 128)          512         dense_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 128)          0           batch_normalization_48[0][0]     \n",
      "                                                                 activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 128)          0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 128)          16512       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 128)          512         dense_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 128)          0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 128)          16512       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 128)          512         dense_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 128)          0           batch_normalization_50[0][0]     \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 128)          0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 10)           1290        activation_50[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 510,858\n",
      "Trainable params: 504,458\n",
      "Non-trainable params: 6,400\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 6s 13ms/step - loss: 0.7171 - accuracy: 0.7761 - val_loss: 0.4243 - val_accuracy: 0.9365\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.2362 - accuracy: 0.9406 - val_loss: 0.2584 - val_accuracy: 0.9581\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.1697 - accuracy: 0.9575 - val_loss: 0.2296 - val_accuracy: 0.9534\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.1380 - accuracy: 0.9653 - val_loss: 0.1515 - val_accuracy: 0.9711\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.1161 - accuracy: 0.9708 - val_loss: 0.1338 - val_accuracy: 0.9727\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.1022 - accuracy: 0.9747 - val_loss: 0.1401 - val_accuracy: 0.9724\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0885 - accuracy: 0.9781 - val_loss: 0.2337 - val_accuracy: 0.9701\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0778 - accuracy: 0.9807 - val_loss: 0.1266 - val_accuracy: 0.9742\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0695 - accuracy: 0.9825 - val_loss: 0.1209 - val_accuracy: 0.9770\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0638 - accuracy: 0.9842 - val_loss: 0.0981 - val_accuracy: 0.9782\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0611 - accuracy: 0.9848 - val_loss: 0.1207 - val_accuracy: 0.9778\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0556 - accuracy: 0.9861 - val_loss: 0.1357 - val_accuracy: 0.9782\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0483 - accuracy: 0.9878 - val_loss: 0.1055 - val_accuracy: 0.9788\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0476 - accuracy: 0.9886 - val_loss: 0.1297 - val_accuracy: 0.9770\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0447 - accuracy: 0.9891 - val_loss: 0.1123 - val_accuracy: 0.9788\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0419 - accuracy: 0.9894 - val_loss: 0.1074 - val_accuracy: 0.9779\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0428 - accuracy: 0.9903 - val_loss: 0.1060 - val_accuracy: 0.9772\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0372 - accuracy: 0.9904 - val_loss: 0.0997 - val_accuracy: 0.9784\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0358 - accuracy: 0.9915 - val_loss: 0.0936 - val_accuracy: 0.9806\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0335 - accuracy: 0.9921 - val_loss: 0.1140 - val_accuracy: 0.9796\n"
     ]
    }
   ],
   "source": [
    "# Create all layers  \n",
    "x_all = fCreate_Layers(n_layers, inputs)\n",
    "# Output layer\n",
    "predictions = Dense(n_classes, activation='softmax')(x_all)\n",
    "print('Output layer added')\n",
    "# Create Model\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n",
    "\n",
    "ttb_dir = './MLP_SKIP_%s' % n_layers\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "\n",
    "model_name = 'MLP_SKIP_%s.h5' % n_layers\n",
    "csv_name = 'MLP_SKIP_%s.csv' % n_layers\n",
    "\n",
    "model.save(model_name)\n",
    "pandas.DataFrame(history.history).to_csv(csv_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st Row - MLP No Skip Connection\n",
    "\n",
    "2nd Row - MLP No Skip Connection No Batch Normalization\n",
    "\n",
    "3rd Row - MLP With Skip Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](vanishingGrads.png \"Effect of adding skip connections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras231]",
   "language": "python",
   "name": "conda-env-keras231-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
