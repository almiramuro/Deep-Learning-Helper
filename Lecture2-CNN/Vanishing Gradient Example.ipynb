{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploding and Vanishing Gradient Demo\n",
    "\n",
    "Source: https://github.com/grasool/explore-gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the depth of a neural netwrok generally leads to increased accuracy. However, with the increasing number of layers in a neural netwroks, the gradients of the loss function with respect to the unknown parameters (weights and biases) may either explode or vanish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.utils import np_utils\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Model\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' ### just to remove memory warnings\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Creates MLP layers \n",
    "Fits the model\n",
    "Saves the model\n",
    "Saves csv for loss and accuracy (trainig and validation)\n",
    "Saves tensorboard summary for Gradients\n",
    "@author: Ghulam Rasool\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Specify number of layers\n",
    "N_LAYERS = 25\n",
    "\n",
    "# Width of hidden layer, number of neurons in the hidden layer. all layers have same width. \n",
    "n_hwidth = 128\n",
    "batch_size = 128\n",
    "n_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "n_layers = N_LAYERS -1\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train, n_classes)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 added\n",
      "Layer 2 added\n",
      "Layer 3 added\n",
      "Layer 4 added\n",
      "Layer 5 added\n",
      "Layer 6 added\n",
      "Layer 7 added\n",
      "Layer 8 added\n",
      "Layer 9 added\n",
      "Layer 10 added\n",
      "Layer 11 added\n",
      "Layer 12 added\n",
      "Layer 13 added\n",
      "Layer 14 added\n",
      "Layer 15 added\n",
      "Layer 16 added\n",
      "Layer 17 added\n",
      "Layer 18 added\n",
      "Layer 19 added\n",
      "Layer 20 added\n",
      "Layer 21 added\n",
      "Layer 22 added\n",
      "Layer 23 added\n",
      "Layer 24 added\n",
      "Output layer added\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 784)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               100480    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_16 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_17 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_18 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_19 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_20 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_21 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_22 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_23 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 493,834\n",
      "Trainable params: 487,690\n",
      "Non-trainable params: 6,144\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 43s 58ms/step - loss: 0.8975 - accuracy: 0.7116 - val_loss: 0.5251 - val_accuracy: 0.9262\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 27s 57ms/step - loss: 0.2765 - accuracy: 0.9333 - val_loss: 0.3532 - val_accuracy: 0.9555\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 26s 55ms/step - loss: 0.2032 - accuracy: 0.9509 - val_loss: 0.3311 - val_accuracy: 0.9568\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 22s 48ms/step - loss: 0.1646 - accuracy: 0.9604 - val_loss: 0.1762 - val_accuracy: 0.9646\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 19s 41ms/step - loss: 0.1424 - accuracy: 0.9656 - val_loss: 0.2812 - val_accuracy: 0.9572\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 19s 40ms/step - loss: 0.1276 - accuracy: 0.9700 - val_loss: 0.1896 - val_accuracy: 0.9655\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 18s 39ms/step - loss: 0.1150 - accuracy: 0.9730 - val_loss: 0.1459 - val_accuracy: 0.9690\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 20s 42ms/step - loss: 0.1020 - accuracy: 0.9764 - val_loss: 0.1625 - val_accuracy: 0.9713\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 25s 53ms/step - loss: 0.0935 - accuracy: 0.9778 - val_loss: 0.1979 - val_accuracy: 0.9703\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 25s 53ms/step - loss: 0.0835 - accuracy: 0.9806 - val_loss: 0.1391 - val_accuracy: 0.9730\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 24s 52ms/step - loss: 0.0771 - accuracy: 0.9821 - val_loss: 0.1774 - val_accuracy: 0.9778\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 25s 53ms/step - loss: 0.0697 - accuracy: 0.9837 - val_loss: 0.1586 - val_accuracy: 0.9737\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 27s 58ms/step - loss: 0.0677 - accuracy: 0.9842 - val_loss: 0.0990 - val_accuracy: 0.9777\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0644 - accuracy: 0.9852 - val_loss: 0.1196 - val_accuracy: 0.9759\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0608 - accuracy: 0.9862 - val_loss: 0.1562 - val_accuracy: 0.9780\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 17s 37ms/step - loss: 0.0555 - accuracy: 0.9872 - val_loss: 0.1065 - val_accuracy: 0.9781\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0577 - accuracy: 0.9877 - val_loss: 0.1308 - val_accuracy: 0.9760\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 0.0503 - accuracy: 0.9879 - val_loss: 0.1320 - val_accuracy: 0.9764\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 0.0462 - accuracy: 0.9898 - val_loss: 0.1075 - val_accuracy: 0.9768\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 16s 34ms/step - loss: 0.0443 - accuracy: 0.9905 - val_loss: 0.1342 - val_accuracy: 0.9760\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(784,))\n",
    "\n",
    "def fCreate_Layers(n_layers, inputs):\n",
    "    x = inputs\n",
    "    for k in range(n_layers):\n",
    "        x = Dense(n_hwidth)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        print('Layer %d added' % (k+1))\n",
    "        \n",
    "    return x\n",
    "\n",
    "# Create all layers    \n",
    "x_all = fCreate_Layers(n_layers, inputs)\n",
    "# Output layer\n",
    "predictions = Dense(n_classes, activation='softmax')(x_all)\n",
    "print('Output layer added')\n",
    "# Create Model\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "model_name = 'MLP_No_SKIP_%s.h5' % N_LAYERS\n",
    "csv_name = 'MLP_No_SKIP_%s.csv' % N_LAYERS\n",
    "\n",
    "model.save(model_name)\n",
    "pandas.DataFrame(history.history).to_csv(csv_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\"\"\"\n",
    "Creates MLP layers with skip connections\n",
    "Fits the model\n",
    "Saves the model\n",
    "Saves csv for loss and accuracy (trainig and validation)\n",
    "Saves tensorboard summary for Gradients\n",
    "@author: Ghulam Rasool\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(784,))\n",
    "\n",
    "def fCreate_Layers(n_layers, inputs):\n",
    "    x = Dense(n_hwidth)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    print('Layer 1 added')\n",
    "    \n",
    "    n_skip_layers = math.floor(n_layers/2)\n",
    "    \n",
    "    for k in range(n_skip_layers):\n",
    "        x = Dense(n_hwidth)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        print('Layer %d added' % (2*k+2))\n",
    "        \n",
    "        y = Dense(n_hwidth)(x)\n",
    "        y = BatchNormalization()(y)\n",
    "        x = keras.layers.add([y, x])\n",
    "        x = Activation('relu')(x)\n",
    "        print('Layer %d with skip connection  added' % (2*k+3))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 added\n",
      "Layer 2 added\n",
      "Layer 3 with skip connection  added\n",
      "Layer 4 added\n",
      "Layer 5 with skip connection  added\n",
      "Layer 6 added\n",
      "Layer 7 with skip connection  added\n",
      "Layer 8 added\n",
      "Layer 9 with skip connection  added\n",
      "Layer 10 added\n",
      "Layer 11 with skip connection  added\n",
      "Layer 12 added\n",
      "Layer 13 with skip connection  added\n",
      "Layer 14 added\n",
      "Layer 15 with skip connection  added\n",
      "Layer 16 added\n",
      "Layer 17 with skip connection  added\n",
      "Layer 18 added\n",
      "Layer 19 with skip connection  added\n",
      "Layer 20 added\n",
      "Layer 21 with skip connection  added\n",
      "Layer 22 added\n",
      "Layer 23 with skip connection  added\n",
      "Layer 24 added\n",
      "Layer 25 with skip connection  added\n",
      "Output layer added\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 784)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 128)          100480      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 128)         512         ['dense_25[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 128)          0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 128)          16512       ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 128)         512         ['dense_26[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 128)          0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 128)          16512       ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 128)         512         ['dense_27[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 128)          0           ['batch_normalization_26[0][0]', \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 128)          0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 128)          16512       ['activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 128)         512         ['dense_28[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 128)          0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 128)          16512       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 128)         512         ['dense_29[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 128)          0           ['batch_normalization_28[0][0]', \n",
      "                                                                  'activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 128)          0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_30 (Dense)               (None, 128)          16512       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 128)         512         ['dense_30[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 128)          0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " dense_31 (Dense)               (None, 128)          16512       ['activation_29[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 128)         512         ['dense_31[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 128)          0           ['batch_normalization_30[0][0]', \n",
      "                                                                  'activation_29[0][0]']          \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 128)          0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_32 (Dense)               (None, 128)          16512       ['activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 128)         512         ['dense_32[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 128)          0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " dense_33 (Dense)               (None, 128)          16512       ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 128)         512         ['dense_33[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 128)          0           ['batch_normalization_32[0][0]', \n",
      "                                                                  'activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 128)          0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_34 (Dense)               (None, 128)          16512       ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 128)         512         ['dense_34[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 128)          0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " dense_35 (Dense)               (None, 128)          16512       ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 128)         512         ['dense_35[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 128)          0           ['batch_normalization_34[0][0]', \n",
      "                                                                  'activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 128)          0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_36 (Dense)               (None, 128)          16512       ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 128)         512         ['dense_36[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 128)          0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " dense_37 (Dense)               (None, 128)          16512       ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 128)         512         ['dense_37[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 128)          0           ['batch_normalization_36[0][0]', \n",
      "                                                                  'activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 128)          0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_38 (Dense)               (None, 128)          16512       ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 128)         512         ['dense_38[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 128)          0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " dense_39 (Dense)               (None, 128)          16512       ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 128)         512         ['dense_39[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 128)          0           ['batch_normalization_38[0][0]', \n",
      "                                                                  'activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 128)          0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_40 (Dense)               (None, 128)          16512       ['activation_38[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 128)         512         ['dense_40[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 128)          0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " dense_41 (Dense)               (None, 128)          16512       ['activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 128)         512         ['dense_41[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 128)          0           ['batch_normalization_40[0][0]', \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 128)          0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_42 (Dense)               (None, 128)          16512       ['activation_40[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 128)         512         ['dense_42[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 128)          0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " dense_43 (Dense)               (None, 128)          16512       ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 128)         512         ['dense_43[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 128)          0           ['batch_normalization_42[0][0]', \n",
      "                                                                  'activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 128)          0           ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_44 (Dense)               (None, 128)          16512       ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 128)         512         ['dense_44[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 128)          0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " dense_45 (Dense)               (None, 128)          16512       ['activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 128)         512         ['dense_45[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 128)          0           ['batch_normalization_44[0][0]', \n",
      "                                                                  'activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 128)          0           ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_46 (Dense)               (None, 128)          16512       ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 128)         512         ['dense_46[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 128)          0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " dense_47 (Dense)               (None, 128)          16512       ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 128)         512         ['dense_47[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 128)          0           ['batch_normalization_46[0][0]', \n",
      "                                                                  'activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 128)          0           ['add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_48 (Dense)               (None, 128)          16512       ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 128)         512         ['dense_48[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 128)          0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " dense_49 (Dense)               (None, 128)          16512       ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 128)         512         ['dense_49[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 128)          0           ['batch_normalization_48[0][0]', \n",
      "                                                                  'activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 128)          0           ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_50 (Dense)               (None, 10)           1290        ['activation_48[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 510,858\n",
      "Trainable params: 504,458\n",
      "Non-trainable params: 6,400\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 34s 36ms/step - loss: 0.7101 - accuracy: 0.7812 - val_loss: 0.5013 - val_accuracy: 0.9335\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.2446 - accuracy: 0.9385 - val_loss: 0.4196 - val_accuracy: 0.9431\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.1761 - accuracy: 0.9560 - val_loss: 0.1797 - val_accuracy: 0.9633\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.1359 - accuracy: 0.9659 - val_loss: 0.1526 - val_accuracy: 0.9676\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 13s 29ms/step - loss: 0.1157 - accuracy: 0.9714 - val_loss: 0.1278 - val_accuracy: 0.9714\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0999 - accuracy: 0.9747 - val_loss: 0.1033 - val_accuracy: 0.9759\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 13s 29ms/step - loss: 0.0855 - accuracy: 0.9783 - val_loss: 0.1456 - val_accuracy: 0.9718\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 13s 29ms/step - loss: 0.0805 - accuracy: 0.9797 - val_loss: 0.1120 - val_accuracy: 0.9755\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0703 - accuracy: 0.9825 - val_loss: 0.1273 - val_accuracy: 0.9761\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0618 - accuracy: 0.9838 - val_loss: 0.1215 - val_accuracy: 0.9767\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0594 - accuracy: 0.9853 - val_loss: 0.1124 - val_accuracy: 0.9755\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0526 - accuracy: 0.9871 - val_loss: 0.1117 - val_accuracy: 0.9762\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0506 - accuracy: 0.9876 - val_loss: 0.4753 - val_accuracy: 0.9528\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0455 - accuracy: 0.9887 - val_loss: 0.1637 - val_accuracy: 0.9790\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0439 - accuracy: 0.9893 - val_loss: 0.0926 - val_accuracy: 0.9813\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 0.0411 - accuracy: 0.9901 - val_loss: 0.0766 - val_accuracy: 0.9828\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0386 - accuracy: 0.9904 - val_loss: 0.0914 - val_accuracy: 0.9806\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0374 - accuracy: 0.9910 - val_loss: 0.1089 - val_accuracy: 0.9786\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0365 - accuracy: 0.9915 - val_loss: 0.0758 - val_accuracy: 0.9841\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0329 - accuracy: 0.9921 - val_loss: 0.0791 - val_accuracy: 0.9823\n"
     ]
    }
   ],
   "source": [
    "# Create all layers  \n",
    "x_all = fCreate_Layers(n_layers, inputs)\n",
    "# Output layer\n",
    "predictions = Dense(n_classes, activation='softmax')(x_all)\n",
    "print('Output layer added')\n",
    "# Create Model\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n",
    "\n",
    "ttb_dir = './MLP_SKIP_%s' % n_layers\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "\n",
    "model_name = 'MLP_SKIP_%s.h5' % n_layers\n",
    "csv_name = 'MLP_SKIP_%s.csv' % n_layers\n",
    "\n",
    "model.save(model_name)\n",
    "pandas.DataFrame(history.history).to_csv(csv_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st Row - MLP No Skip Connection\n",
    "\n",
    "2nd Row - MLP No Skip Connection No Batch Normalization\n",
    "\n",
    "3rd Row - MLP With Skip Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](vanishingGrads.png \"Effect of adding skip connections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c1e96344996f3058d8883c930bd2ba75d2406938ac81fce909d07c2e4ab2939"
  },
  "kernelspec": {
   "display_name": "Python [conda env:keras231]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
