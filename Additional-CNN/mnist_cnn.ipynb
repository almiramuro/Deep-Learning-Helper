{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is based on the tutorial of Mark Jay in Youtube \n",
    "# (Part 1 - https://www.youtube.com/watch?v=N3oMKS1AfVI) \n",
    "# (Part 2 - https://www.youtube.com/watch?v=lOZGYzTn9Z8) \n",
    "\n",
    "#  libraries important for the models\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.optimizers import adam_v2\n",
    "\n",
    "#  libraries important for importing the data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0        30        43         0   \n",
       "3       0  ...         3         0         0         0         0         1   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the dataset\n",
    "\n",
    "train_df = pd.read_csv(r'fashion-mnist_train.csv')\n",
    "test_df = pd.read_csv(r'fashion-mnist_test.csv')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the dataframes to numpy arrays for compatibility input\n",
    "\n",
    "train_data = np.array(train_df, dtype='float32') #when working with tensorflow, every dtype will either be int32 or float32\n",
    "test_data = np.array(test_df, dtype='float32')\n",
    "\n",
    "#looking at the dataframe above, the value of the pixels range from 0 to 255 so in order to make the values from 0 to 1 only, we divide everything by 255 as shown below\n",
    "\n",
    "#slice arrays\n",
    "x_train = train_data[:, 1:] / 255  #take every single row, slice on the columns from column 1\n",
    "y_train = train_data[:, 0]   #take every single row, but only take column 0\n",
    "\n",
    "x_test = test_data[:, 1:] / 255\n",
    "y_test = test_data[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (48000, 784)\n",
      "x_validate shape: (12000, 784)\n",
      "y_train shape: (48000,)\n",
      "y_validate shape: (12000,)\n"
     ]
    }
   ],
   "source": [
    "#divide the training data into validation data and actual training data\n",
    "\n",
    "#returns 4 different arrays\n",
    "x_train, x_validate, y_train, y_validate = train_test_split(\n",
    "    x_train, y_train,           # the arrays we want to split up\n",
    "    test_size = 0.2,            # how much you wanna split the train data into train-validate (test_size = validate size)\n",
    "    random_state = 12345        # specifies how the stuff will be split into the training and validation data (not sure what the 12345 stands for though)\n",
    ")\n",
    "\n",
    "print('x_train shape: {}'.format(x_train.shape))\n",
    "print('x_validate shape: {}'.format(x_validate.shape))\n",
    "print('y_train shape: {}'.format(y_train.shape))\n",
    "print('y_validate shape: {}'.format(y_validate.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#see visualizations\n",
    "\n",
    "# take one row from the train data and take all columns\n",
    "image = x_train[55, :].reshape((28,28))    # this is a row that is 784 long. we need to reshape to the original image shape which is 28 x 28\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the CNN \n",
    "- Define the model\n",
    "- Compile the model\n",
    "- Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (48000, 28, 28, 1)\n",
      "x_test shape: (10000, 28, 28, 1)\n",
      "x_validate shape: (12000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#define the shape of the image\n",
    "\n",
    "im_rows = 28\n",
    "im_cols = 28\n",
    "batch_size = 512                    # \n",
    "im_shape = (im_rows, im_cols, 1)    # shape is rows x cols x 1; 1 because it is 2D\n",
    "\n",
    "#formatting the x_train test validation\n",
    "x_train = x_train.reshape(x_train.shape[0],*im_shape)\n",
    "x_test = x_test.reshape(x_test.shape[0],*im_shape)\n",
    "x_validate = x_validate.reshape(x_validate.shape[0],*im_shape)\n",
    "\n",
    "print('x_train shape: {}'.format(x_train.shape))\n",
    "print('x_test shape: {}'.format(x_test.shape))\n",
    "print('x_validate shape: {}'.format(x_validate.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE the model\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    #one layer\n",
    "    Conv2D(\n",
    "        filters = 32,           # specifies the output dimension of the layer\n",
    "        kernel_size = 3,        # kernel size 3 by 3\n",
    "        activation = 'relu',\n",
    "        input_shape = im_shape\n",
    "    ),\n",
    "    MaxPooling2D(               # down sampling the output\n",
    "        pool_size = 2           # 28 by 28 images will be downsized (height and width) by a factor of 2\n",
    "    ),\n",
    "    Dropout(0.2),               # randomly drop out certain connections to the next layer\n",
    "    Flatten(),                  # flatten all the layers\n",
    "    Dense(                      \n",
    "        32,                     # \"Filter\" units specifies the output dimension of the layer\n",
    "        activation = 'relu'\n",
    "    ),          \n",
    "    Dense(\n",
    "        10,                     # \"Filter\" units specifies the output dimension of the layer\n",
    "        activation ='softmax'   # softmax is preferred activation for an output layer (pls read more about this)\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
     ]
    }
   ],
   "source": [
    "# Logging some data to a file using tensorboard\n",
    "\n",
    "tensorboard = tf.compat.v1.keras.callbacks.TensorBoard(\n",
    "    log_dir = r'logs/{}'.format('cnn_1layer'),\n",
    "    write_graph = True,\n",
    "    write_grads = True,\n",
    "    histogram_freq = 1,\n",
    "    write_images = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "cnn_model.compile(\n",
    "    loss = 'sparse_categorical_crossentropy',           # read more about the loss\n",
    "    optimizer = 'adam',                                 # lr = learning rate; read about Adam\n",
    "    metrics = ['accuracy']                              # specify which things we want to minimize/maximize (in this application, maximize accuracy)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28, 28, 1)\n",
      "(12000, 28, 28, 1)\n",
      "Epoch 1/10\n",
      "94/94 [==============================] - 23s 221ms/step - loss: 0.7714 - accuracy: 0.7340 - val_loss: 0.5170 - val_accuracy: 0.7980\n",
      "Epoch 2/10\n",
      "94/94 [==============================] - 21s 226ms/step - loss: 0.4432 - accuracy: 0.8412 - val_loss: 0.4009 - val_accuracy: 0.8618\n",
      "Epoch 3/10\n",
      "94/94 [==============================] - 27s 288ms/step - loss: 0.3852 - accuracy: 0.8656 - val_loss: 0.3618 - val_accuracy: 0.8751\n",
      "Epoch 4/10\n",
      "94/94 [==============================] - 31s 327ms/step - loss: 0.3531 - accuracy: 0.8758 - val_loss: 0.3392 - val_accuracy: 0.8814\n",
      "Epoch 5/10\n",
      "94/94 [==============================] - 25s 265ms/step - loss: 0.3334 - accuracy: 0.8825 - val_loss: 0.3166 - val_accuracy: 0.8888\n",
      "Epoch 6/10\n",
      "94/94 [==============================] - 21s 222ms/step - loss: 0.3193 - accuracy: 0.8877 - val_loss: 0.3162 - val_accuracy: 0.8860\n",
      "Epoch 7/10\n",
      "94/94 [==============================] - 27s 287ms/step - loss: 0.3067 - accuracy: 0.8901 - val_loss: 0.3018 - val_accuracy: 0.8928\n",
      "Epoch 8/10\n",
      "94/94 [==============================] - 33s 347ms/step - loss: 0.2927 - accuracy: 0.8960 - val_loss: 0.2887 - val_accuracy: 0.8994\n",
      "Epoch 9/10\n",
      "94/94 [==============================] - 31s 325ms/step - loss: 0.2895 - accuracy: 0.8970 - val_loss: 0.2878 - val_accuracy: 0.8983\n",
      "Epoch 10/10\n",
      "94/94 [==============================] - 29s 308ms/step - loss: 0.2763 - accuracy: 0.9026 - val_loss: 0.2784 - val_accuracy: 0.9018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cb3aec8f40>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIT the model\n",
    "print(x_train.shape)\n",
    "print(x_validate.shape)\n",
    "cnn_model.fit(\n",
    "    x_train, y_train, \n",
    "    batch_size = batch_size,                            # how many rows of data is used for each step of stochastic gradient descent\n",
    "    epochs = 10,\n",
    "    verbose = 1,                                        # Verbose = set to true, Keras will print a log\n",
    "    validation_data = (x_validate, y_validate),\n",
    "    callbacks = [tensorboard]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cnn_model.evaluate(x_test, y_test, verbose = 0)\n",
    "\n",
    "print('test loss: {:.4f}'.format(score[0]))\n",
    "print('test acc: {:.4f}'.format(score[1]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c1e96344996f3058d8883c930bd2ba75d2406938ac81fce909d07c2e4ab2939"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 ('dl_helper')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
